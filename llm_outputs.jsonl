[
  {
    "query_id": "organs__sha256:964d12658b6afaff9ab94d39f87197d221f746d7fda95289b7d5d4f4c5f649b9",
    "query_label": "organs-0001",
    "kg_id": "organs",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "List all organs and their labels.",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No suitable evidence phrases match this simple listing query, but the SPARQL clearly selects all instances of organ:Organ with their rdfs:label values. Confidence is moderate due to lack of corroborating NL evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 13136
  },
  {
    "query_id": "organs__sha256:6f461a51ed2b5002c8bdbc23ad9460892a4bcc2cb76c6ad6076ea8d994445837",
    "query_label": "organs-0002",
    "kg_id": "organs",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "What are the names of the organs Part15_021AlphenaandenRijn, OI-ee4e8485b89314b0555e15c5b0b7181c, and FR-67462-SELES-STFOYY1-X?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No evidence directly matches this query, so the question is generated from the SPARQL, which clearly selects rdfs:label values for three specific organ IRIs. The query intent is straightforward, but lack of aligned evidence lowers confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 21463
  },
  {
    "query_id": "organs__sha256:102819bf18137c32e63d4a9e845be95d8bf02f91894e00cffb5f46ee154d3662",
    "query_label": "organs-0003",
    "kg_id": "organs",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "When was each of the specified organs built?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "The SPARQL clearly selects the time (and its label) from an OrganProject classified as a build task for a given set of organs, indicating build dates. However, there is no suitable natural-language evidence matching this intent, so the question is generated from the query alone.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 22631
  },
  {
    "query_id": "organs__sha256:4b50368649ac2e9e22b216e61ded40976efe40d57e01bad4d7365cc9ce3150c4",
    "query_label": "organs-0004",
    "kg_id": "organs",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "What descriptions are recorded for the organs Part15_021AlphenaandenRijn, OI-ee4e8485b89314b0555e15c5b0b7181c, and FR-67462-SELES-STFOYY1-X?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 68,
      "confidence_rationale": "No provided evidence directly matches retrieving an organ’s description, so the question is generated from the SPARQL structure. The query clearly selects the description values for three specified organ IRIs, but lack of aligned evidence reduces confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 25564
  },
  {
    "query_id": "organs__sha256:2a9530e82bf299eebc7ec74b5133b725b7cb139b83151243bd1ad4fa97e3556a",
    "query_label": "organs-0005",
    "kg_id": "organs",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Which organs are located in the same city or were built by the same builder as a given organ?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No direct evidence describes finding organs that share the same city or builder; the question is generated from the SPARQL pattern matching on shared city and shared builder (including disambiguated names). The SPARQL intent is clear, but absence of matching NL evidence lowers confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 31581
  },
  {
    "query_id": "organs__sha256:12c9b771057e418f7b01614dde3364d73df92b4e77ef25790cf4935b3e555aaa",
    "query_label": "organs-0006",
    "kg_id": "organs",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "When is an organ moved to another location?",
          "evidence_id": "e7",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": true
        },
        {
          "text": "Where is an organ located originally?",
          "evidence_id": "e6",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": true
        }
      ],
      "nl_question": "When and where was the organ Part12_062 Rhenen Gereformeerde most recently located?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "The SPARQL clearly retrieves the latest time and location details (name, address, city, coordinates) for a specific organ by ordering times descending and limiting to one result. Available CQ evidence touches on time and location but does not precisely match the 'most recent timed location' intent, so the question is generated from the query with moderate confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 37098
  },
  {
    "query_id": "organs__sha256:d58004b5c946f95f9c95b6ebce5cb13203e3d45de47cad23791cce1ad0ff5733",
    "query_label": "organs-0007",
    "kg_id": "organs",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Which building tasks are defined in the organ projects for the selected organs?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No suitable evidence matches the query’s focus on project-defined build tasks, so the question is generated from the SPARQL structure. The query clearly retrieves tasks classified as build that are defined by the organ’s project for specific organs, but lack of supporting text lowers confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 27287
  },
  {
    "query_id": "organs__sha256:8ad8353f60e43afae6ad0e1dad1642a448977527d26ae968099406c3a60d9617",
    "query_label": "organs-0008",
    "kg_id": "organs",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "What is the primary image URL and caption for each of the specified organs?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "The SPARQL clearly queries each given organ for a picture marked as primary, returning its URL and an optional caption. No provided evidence mentions images, so the question is generated directly from the query, lowering confidence despite the straightforward intent.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 17417
  },
  {
    "query_id": "organs__sha256:7b88d1f487d64c1c67e3579f8228943b90e1affe380ba3de943b9143ec3182a2",
    "query_label": "organs-0009",
    "kg_id": "organs",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "Who built an organ?",
          "evidence_id": "e12",
          "source_type": "web_query_desc",
          "rank": 1,
          "verbatim": true
        },
        {
          "text": "Who built and/or renovated an organ?",
          "evidence_id": "e2",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": true
        }
      ],
      "nl_question": "Who built an organ?",
      "nl_question_origin": {
        "mode": "verbatim",
        "evidence_ids": [
          "e12",
          "e2"
        ],
        "primary_evidence_id": "e12"
      },
      "confidence": 91,
      "confidence_rationale": "The query filters for agent roles where the role is 'builder' in projects describing organs, which aligns directly with the evidence phrase 'Who built an organ?'. The match is strong and specific, though the query omits an explicit binding for ?agent, which slightly tempers confidence.",
      "needs_review": false
    },
    "model": "gpt-5",
    "elapsed_ms": 26221
  },
  {
    "query_id": "meetups__sha256:7735c659b6b4b3d86c7c77b7f83ee34f50c7227d81665b5cfff56cb11912fa72",
    "query_label": "meetups-0001",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many meetups, excerpts, persons mentioned, distinct subjects, distinct places, and time expressions are recorded in the Meetups knowledge graph?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "The SPARQL clearly aggregates counts for meetups, evidence texts, participants, subjects, places, and time expressions, so the question is derived directly from the query structure. No provided evidence specifically describes this summary/counts query, reducing confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 19579
  },
  {
    "query_id": "meetups__sha256:80e346ff0bc7535c4867d90ef22b6b3499bf1b572bc70c77e3d20673c6ab6c0e",
    "query_label": "meetups-0002",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "Did musician X and performer Y ever meet?",
          "evidence_id": "e3",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": true
        },
        {
          "text": "What was the composer’s network?",
          "evidence_id": "e41",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": true
        }
      ],
      "nl_question": "Which people most frequently met with Edward Elgar, and how many times?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e3",
          "e41"
        ],
        "primary_evidence_id": "e3"
      },
      "confidence": 78,
      "confidence_rationale": "The SPARQL clearly finds co-participants in meetups with Edward Elgar and counts their occurrences, matching the idea of who met whom and the composer's network. However, the evidence does not explicitly mention ranking by frequency or counts, so the final question required some inference from the query.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 61324
  },
  {
    "query_id": "meetups__sha256:84bb45b9bee95e892ca8f9734a3658c0181d236f694015890237ec577330bdde",
    "query_label": "meetups-0003",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "What places did musician Z visit in her career?",
          "evidence_id": "e2",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": false
        },
        {
          "text": "Where did musician X and performer Y meet?",
          "evidence_id": "e3",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": false
        },
        {
          "text": "What places did musician Z visit in his/her career?",
          "evidence_id": "e34",
          "source_type": "cq_item",
          "rank": 3,
          "verbatim": false
        }
      ],
      "nl_question": "What are the two places most frequently associated with meetups involving Edward Elgar?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e2",
          "e3",
          "e34"
        ],
        "primary_evidence_id": "e2"
      },
      "confidence": 82,
      "confidence_rationale": "The SPARQL groups Edward Elgar’s meetups by place, orders by count, and returns the top two, clearly indicating a \"most frequent places\" intent. The retained CQ items support the place/where dimension for a musician’s meetups, though they don’t explicitly mention frequency or top-N, so some paraphrasing was required.",
      "needs_review": false
    },
    "model": "gpt-5",
    "elapsed_ms": 51199
  },
  {
    "query_id": "meetups__sha256:06b128c0b7124f36cc1eb8ed14c43f8b5476f734dc0b19797ef0e71dc8d124e7",
    "query_label": "meetups-0004",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "What is the nature of the event?",
          "evidence_id": "e5",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": true
        },
        {
          "text": "Was it a celebration, a festival, a private event?",
          "evidence_id": "e6",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": true
        },
        {
          "text": "Why did musician X and performer Y meet? Purpose / Meetup type why?",
          "evidence_id": "e36",
          "source_type": "cq_item",
          "rank": 3,
          "verbatim": true
        },
        {
          "text": "In what context the meeting happened?",
          "evidence_id": "e4",
          "source_type": "cq_item",
          "rank": 4,
          "verbatim": true
        }
      ],
      "nl_question": "For meetups involving Edward Elgar, how many were of each event purpose or type?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e5",
          "e6",
          "e36",
          "e4"
        ],
        "primary_evidence_id": "e5"
      },
      "confidence": 85,
      "confidence_rationale": "The SPARQL groups Edward Elgar’s meetups by mtp:hasAPurpose and counts them, which aligns well with CQs about the event’s nature/type and purpose. The counting aspect is inferred from the query’s aggregation but is consistent with the intent of the cited CQs.",
      "needs_review": false
    },
    "model": "gpt-5",
    "elapsed_ms": 45261
  },
  {
    "query_id": "meetups__sha256:2a8e02076ebd39d9c5c8725837b989b8327be0b18f010ced4fd7e6eb12733560",
    "query_label": "meetups-0005",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Which subjects have matching file names in both infoBiographies.csv and list_wikiIdSample.csv, and what is the file ID (the file name without “.txt”)?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 68,
      "confidence_rationale": "No usable evidence aligns with the query; the question is derived from the SPARQL structure, which clearly joins two CSVs on fileName and outputs the subject and a fileId created by stripping “.txt”. Lack of corroborating NL evidence lowers confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 21238
  },
  {
    "query_id": "meetups__sha256:0023c7e04fc8497295d6915c944e52aee4166237f817be28d0f230c1a36d9812",
    "query_label": "meetups-0006",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "Purpose / Meetup type why?",
          "evidence_id": "e36",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": true
        },
        {
          "text": "Purpose / Event why?",
          "evidence_id": "e24",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": true
        },
        {
          "text": "What is the nature of the event?",
          "evidence_id": "e28",
          "source_type": "cq_item",
          "rank": 3,
          "verbatim": true
        },
        {
          "text": "Was it a celebration, a festival, a private event?",
          "evidence_id": "e29",
          "source_type": "cq_item",
          "rank": 4,
          "verbatim": true
        },
        {
          "text": "Was it a religious or a secular event?",
          "evidence_id": "e30",
          "source_type": "cq_item",
          "rank": 5,
          "verbatim": true
        }
      ],
      "nl_question": "Which meetup purposes (types) are available in the Meetups knowledge graph?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e36",
          "e24",
          "e28",
          "e29",
          "e30"
        ],
        "primary_evidence_id": "e36"
      },
      "confidence": 78,
      "confidence_rationale": "The SPARQL selects all instances of mtp:Purpose with labels, aligning with evidence phrases about meetup purpose/type and event nature. However, the evidence questions focus on specific events rather than listing all purposes, so some inference was required.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 50969
  },
  {
    "query_id": "meetups__sha256:4985d6f1f15f8d1ea40a262b5894b7e1f498aa2f86e3126912ce8012792f03e1",
    "query_label": "meetups-0007",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Which people are the main subjects of analysis in the MEETUPS knowledge graph, and what are their labels?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 68,
      "confidence_rationale": "No provided evidence directly matches this query. The question is generated from the SPARQL, which selects all resources linked via mtp:hasSubject and their rdfs:labels, implying the set of people who are subjects in the MEETUPS KG.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 27673
  },
  {
    "query_id": "meetups__sha256:ceeac221b1b9a7612e551d819ab082e70a3c0ca323d2433ce3e97d23bdc39c14",
    "query_label": "meetups-0008",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Which locations in the Meetups knowledge graph (with their labels) have latitude and longitude coordinates?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 68,
      "confidence_rationale": "No provided evidence directly describes listing all locations with coordinates; competency questions focus on musician-specific places or meetings. The SPARQL intent is clear (locations with existing lat/long and their labels), so the question is generated from the query structure.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 35163
  },
  {
    "query_id": "meetups__sha256:e6ef15276a364c025ba5bb1b59205c5618be7e209f3a9f277720416094281862",
    "query_label": "meetups-0009",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "Did musician X and performer Y ever meet?",
          "evidence_id": "e3",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": true
        },
        {
          "text": "Participants who?",
          "evidence_id": "e20",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": true
        },
        {
          "text": "Where did musician X and performer Y meet?",
          "evidence_id": "e35",
          "source_type": "cq_item",
          "rank": 3,
          "verbatim": true
        }
      ],
      "nl_question": "Who did Yehudi Menuhin share a meetup with?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e3",
          "e20",
          "e35"
        ],
        "primary_evidence_id": "e3"
      },
      "confidence": 84,
      "confidence_rationale": "The SPARQL finds co-participants of Yehudi Menuhin in meetup events and labels them, which aligns well with the CQs about whether two people met and identifying participants. The final question paraphrases these CQs to match the query’s list-style output.",
      "needs_review": false
    },
    "model": "gpt-5",
    "elapsed_ms": 40640
  },
  {
    "query_id": "meetups__sha256:f130d3ef2939f1d1bd0e5c66fbe14a5394bd5ffb037e54bb9c79e13c44104d2e",
    "query_label": "meetups-0010",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "What places did musician Z visit in her career?",
          "evidence_id": "e2",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": false
        },
        {
          "text": "What places did musician Z visit in his/her career?",
          "evidence_id": "e34",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": false
        },
        {
          "text": "What places did musician Z visit in her career?",
          "evidence_id": "e15",
          "source_type": "cq_item",
          "rank": 3,
          "verbatim": false
        }
      ],
      "nl_question": "What places did Yehudi Menuhin visit in his career?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e2",
          "e34",
          "e15"
        ],
        "primary_evidence_id": "e2"
      },
      "confidence": 92,
      "confidence_rationale": "The SPARQL retrieves places associated with meetup events for the subject Yehudi Menuhin, aligning directly with competency questions about the places a musician visited in their career. Multiple high-priority CQ items from the repo and docs match this intent closely.",
      "needs_review": false
    },
    "model": "gpt-5",
    "elapsed_ms": 41369
  },
  {
    "query_id": "meetups__sha256:873269f24509b8876a9a8b58ab83b778dee136fdc7818eda47fb81e9776e6e84",
    "query_label": "meetups-0011",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "Did musician X and performer Y ever meet? Where, when, and why?",
          "evidence_id": "e3",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": true
        },
        {
          "text": "Where did musician X and performer Y meet?",
          "evidence_id": "e35",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": true
        },
        {
          "text": "When did musician X and performer Y meet?",
          "evidence_id": "e38",
          "source_type": "cq_item",
          "rank": 3,
          "verbatim": true
        },
        {
          "text": "Why did musician X and performer Y meet?",
          "evidence_id": "e36",
          "source_type": "cq_item",
          "rank": 4,
          "verbatim": true
        },
        {
          "text": "What is the nature of the event?",
          "evidence_id": "e5",
          "source_type": "cq_item",
          "rank": 5,
          "verbatim": true
        }
      ],
      "nl_question": "What meetups involving Edward Elgar took place—with which participants, where (including latitude and longitude), when, and for what purpose?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e3",
          "e35",
          "e38",
          "e36",
          "e5"
        ],
        "primary_evidence_id": "e3"
      },
      "confidence": 89,
      "confidence_rationale": "The SPARQL selects meetups for Edward Elgar and returns participants, place (with coordinates), time, and purpose, which aligns closely with CQ items asking where, when, and why meetings occurred. The final question paraphrases high-priority README CQ text and adds participants/coordinates to reflect the query output.",
      "needs_review": false
    },
    "model": "gpt-5",
    "elapsed_ms": 53152
  },
  {
    "query_id": "meetups__sha256:7544d7e24a9471f048c3835d71a91488248b329367048114c279b070b34e40d1",
    "query_label": "meetups-0012",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "Where, when, and why?",
          "evidence_id": "e3",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": true
        },
        {
          "text": "In what context the meeting happened?",
          "evidence_id": "e4",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": true
        },
        {
          "text": "Where did musician X and performer Y meet?",
          "evidence_id": "e35",
          "source_type": "cq_item",
          "rank": 3,
          "verbatim": true
        },
        {
          "text": "When did musician X and performer Y meet?",
          "evidence_id": "e38",
          "source_type": "cq_item",
          "rank": 4,
          "verbatim": true
        }
      ],
      "nl_question": "Who did Al Wilson (singer) meet, where and when did these meetups occur, and for what purpose?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e3",
          "e4",
          "e35",
          "e38"
        ],
        "primary_evidence_id": "e3"
      },
      "confidence": 88,
      "confidence_rationale": "The SPARQL targets meetups for Al Wilson (singer) and returns other participants, locations, time expressions, and purpose. This aligns well with CQ items asking where, when, and why meetings occurred, plus meeting context. Minor paraphrasing was needed to tailor the generic CQs to the specific subject.",
      "needs_review": false
    },
    "model": "gpt-5",
    "elapsed_ms": 77958
  },
  {
    "query_id": "meetups__sha256:9d251bc8571a44524bfd21febfe041a1b046e21301ed47082d47c3bee4f8716b",
    "query_label": "meetups-0013",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "What places did musician Z visit in her career?",
          "evidence_id": "e2",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": false
        },
        {
          "text": "What places did musician Z visit in his/her career?",
          "evidence_id": "e34",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": true
        }
      ],
      "nl_question": "Which places did Al Wilson (singer) visit during his career, and what are their coordinates?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e2",
          "e34"
        ],
        "primary_evidence_id": "e2"
      },
      "confidence": 83,
      "confidence_rationale": "Strong alignment: the query fixes the subject to Al Wilson and retrieves places (with lat/long), matching the competency questions about which places a musician visited. The inclusion of coordinates is inferred from the SPARQL rather than stated explicitly in the evidence, slightly lowering confidence.",
      "needs_review": false
    },
    "model": "gpt-5",
    "elapsed_ms": 79968
  },
  {
    "query_id": "meetups__sha256:845a011b704215ea1adfa6dd775e42e566e94ca5df566a67052376a0e9b16e65",
    "query_label": "meetups-0014",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many meetups, excerpts, person mentions, subjects, place mentions, and time expressions are recorded in the dataset?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No evidence directly describes this aggregation query, so the question is generated from the SPARQL structure. The query clearly counts totals for meetups, excerpts, persons mentioned, subjects, place mentions, and time expressions, yielding moderate confidence without supporting NL evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 28655
  },
  {
    "query_id": "meetups__sha256:6371ee2e85f63544f2310414a0a06c6322b72b2b93f5fbaee0513d4abbd8c8b4",
    "query_label": "meetups-0015",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "When did musician X and performer Y meet?",
          "evidence_id": "e38",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": false
        },
        {
          "text": "When did musician X and performer Y meet?",
          "evidence_id": "e22",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": false
        }
      ],
      "nl_question": "When did Niccolò Paganini’s meetups occur, and what start and end dates are available?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e38",
          "e22"
        ],
        "primary_evidence_id": "e38"
      },
      "confidence": 84,
      "confidence_rationale": "The SPARQL targets time expressions (and optional start/end dates) for meetups involving Niccolò Paganini. CQ items explicitly ask about the time of meetings, which closely matches the query’s temporal focus, though the evidence frames it as a two-person meetup.",
      "needs_review": false
    },
    "model": "gpt-5",
    "elapsed_ms": 67111
  },
  {
    "query_id": "meetups__sha256:295a430d9de1755b2e64fb7cd77083c0a618d58f79bf9ba2b007e0a72e80020c",
    "query_label": "meetups-0016",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "When did musician X and performer Y meet? Temporal when?",
          "evidence_id": "e38",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": true
        },
        {
          "text": "When did musician X and performer Y meet? Time when?",
          "evidence_id": "e22",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": true
        },
        {
          "text": "Did musician X and performer Y ever meet? Where, when, and why?",
          "evidence_id": "e3",
          "source_type": "cq_item",
          "rank": 3,
          "verbatim": true
        }
      ],
      "nl_question": "Which meetups involving Niccolò Paganini, with recorded start and end dates, occurred from 1900 onward, and what were those dates?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e38",
          "e22",
          "e3"
        ],
        "primary_evidence_id": "e38"
      },
      "confidence": 78,
      "confidence_rationale": "The SPARQL targets meetups for Niccolò Paganini and filters on the beginning date (>= 1900), retrieving start/end dates when available. Retained CQs focus on the temporal aspect of meetings, which aligns with the query’s time-based intent, though they mention two participants and no date cutoff, so some paraphrasing and inference were required.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 66787
  },
  {
    "query_id": "meetups__sha256:a291a050385c434b5acf7eb6bb90754bcb2aa29ff70c88615a8b4f9bf24b19fc",
    "query_label": "meetups-0017",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many biographies are in the Meetups Knowledge Graph?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 66,
      "confidence_rationale": "No provided evidence matches this counting/biography query, so the question is generated from the SPARQL, which clearly counts distinct persons linked as subjects. Lack of aligned evidence lowers confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 35790
  },
  {
    "query_id": "meetups__sha256:94f843d738690e4dd64e451b2ce4aaa22dfb2fb92ed91d73a964ddc99f0e9534",
    "query_label": "meetups-0018",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "What is the nature of the event?",
          "evidence_id": "e5",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": true
        },
        {
          "text": "Was it a celebration, a festival, a private event?",
          "evidence_id": "e6",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": true
        },
        {
          "text": "Was it a religious or a secular event?",
          "evidence_id": "e7",
          "source_type": "cq_item",
          "rank": 3,
          "verbatim": true
        }
      ],
      "nl_question": "What is the total number of meetups of type HM?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "The SPARQL clearly counts distinct subjects filtered by a type matching \"HM\", so the generated question aligns with the query’s structure. Available evidence only touches on event/meetup types in general, not on counting or the specific HM category, so alignment is partial and requires some inference.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 70146
  },
  {
    "query_id": "meetups__sha256:e45e754946438660def034acecaaa3095b1def2b3f200157ce4e37d4729c279c",
    "query_label": "meetups-0019",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many distinct people participated in HM-type meetups?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "The SPARQL clearly counts DISTINCT person IRIs linked as participants to events whose type string matches \"HM\". No provided evidence directly addresses a global count of participants, so the question is generated from query semantics, with slight ambiguity about what \"HM\" denotes.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 39114
  },
  {
    "query_id": "meetups__sha256:88033ac75efdd3c79207f8adc125aae5618c6392ad0af01920c0bf3018b950bb",
    "query_label": "meetups-0020",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many distinct places are mentioned in HM-type meetups?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 66,
      "confidence_rationale": "No suitable evidence directly describes this aggregate count. The SPARQL clearly counts distinct place entities linked to items with a type matching \"HM\", so the question is generated from the query structure. Confidence is moderate due to the unexplained meaning of \"HM\" and lack of aligned evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 31449
  },
  {
    "query_id": "meetups__sha256:b8009d6ad459dcee177ddf7fa4f517b88493e229d255c4397a96f265d7e185c8",
    "query_label": "meetups-0021",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many temporal expressions are associated with HM-type meetups?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 68,
      "confidence_rationale": "The SPARQL clearly counts distinct mtp:TimeExpression values linked via mtp:happensAt for resources whose type matches 'HM'. However, no provided evidence directly addresses counting temporal expressions or the 'HM' type, so the question is generated from the query alone.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 28047
  },
  {
    "query_id": "meetups__sha256:0cb40234f95e8fa595cbf7c9167dc4397668f458fc0deb6f5228c466403237ce",
    "query_label": "meetups-0022",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "What places did musician Z visited in her career?",
          "evidence_id": "e2",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": true
        },
        {
          "text": "What places did musician Z visit in his/her career?",
          "evidence_id": "e34",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": false
        },
        {
          "text": "What places did musician Z visit in her career?",
          "evidence_id": "e15",
          "source_type": "cq_item",
          "rank": 3,
          "verbatim": false
        }
      ],
      "nl_question": "What places did Clara Schumann visit in her career?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e2",
          "e34",
          "e15"
        ],
        "primary_evidence_id": "e2"
      },
      "confidence": 96,
      "confidence_rationale": "The SPARQL selects place entities and labels for a specific musician (Clara Schumann), matching the competency question about places a musician visited in their career. Multiple cq_item sources state this question directly, so alignment is strong and unambiguous.",
      "needs_review": false
    },
    "model": "gpt-5",
    "elapsed_ms": 45873
  },
  {
    "query_id": "meetups__sha256:fb8b2f8aba5b0ef65e7c902f5bf94929c7ad85b99223dfaf25b77255cf853847",
    "query_label": "meetups-0023",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "Where did musician X and performer Y meet?",
          "evidence_id": "e16",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": true
        },
        {
          "text": "Where did musician X and performer Y meet?",
          "evidence_id": "e35",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": true
        }
      ],
      "nl_question": "Where did Clara Schumann and another performer meet?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e16",
          "e35"
        ],
        "primary_evidence_id": "e16"
      },
      "confidence": 92,
      "confidence_rationale": "Strong match: the query fixes X to Clara Schumann and retrieves meeting places and participants, directly aligning with the competency question 'Where did musician X and performer Y meet?'. Minor paraphrasing adapts the generic CQ to the specific subject.",
      "needs_review": false
    },
    "model": "gpt-5",
    "elapsed_ms": 32871
  },
  {
    "query_id": "meetups__sha256:b6cf8024b06f51570b867b653d5cb3156f1487d67ada31098fe026ab75a1f691",
    "query_label": "meetups-0024",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "Why did musician X and performer Y meet?",
          "evidence_id": "e27",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": true
        },
        {
          "text": "Why did musician X and performer Y meet?",
          "evidence_id": "e36",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": true
        },
        {
          "text": "Did musician X and performer Y ever meet? Where, when, and why?",
          "evidence_id": "e3",
          "source_type": "cq_item",
          "rank": 3,
          "verbatim": true
        }
      ],
      "nl_question": "Why did Clara Schumann and Joseph Joachim meet?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e27",
          "e36",
          "e3"
        ],
        "primary_evidence_id": "e27"
      },
      "confidence": 95,
      "confidence_rationale": "The SPARQL filters a specific subject (Clara Schumann) and participant (Joseph Joachim) and retrieves the meeting purpose label, directly aligning with CQ items asking why the two met. Multiple strong, matching CQ phrases support the interpretation.",
      "needs_review": false
    },
    "model": "gpt-5",
    "elapsed_ms": 55474
  },
  {
    "query_id": "meetups__sha256:2a7fe691c1b160e3276c5fa9606d1a7c1a9850df68ae3b7e5137c86b8dad39a0",
    "query_label": "meetups-0025",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "When did musician X and performer Y meet?",
          "evidence_id": "e22",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": true
        },
        {
          "text": "When did musician X and performer Y meet?",
          "evidence_id": "e38",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": true
        }
      ],
      "nl_question": "When did Clara Schumann and Joseph Joachim meet?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e22",
          "e38"
        ],
        "primary_evidence_id": "e22"
      },
      "confidence": 95,
      "confidence_rationale": "The SPARQL fixes the two participants (Clara Schumann and Joseph Joachim) and retrieves normalized time values for their meeting events, directly aligning with the CQ phrasing. Two high-quality CQ items explicitly ask the same temporal question, supporting a precise paraphrase.",
      "needs_review": false
    },
    "model": "gpt-5",
    "elapsed_ms": 30660
  },
  {
    "query_id": "meetups__sha256:2a274fe373e270e9e6ee84726e487d660241400f15e5b13ffc045f09a8faf2b9",
    "query_label": "meetups-0026",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "Who other musicians were working at the same time?",
          "evidence_id": "e20",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": false
        },
        {
          "text": "Who other musicians were working at the same time?",
          "evidence_id": "e40",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": false
        }
      ],
      "nl_question": "Which other musicians were active at the same time as Clara Schumann?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e20",
          "e40"
        ],
        "primary_evidence_id": "e20"
      },
      "confidence": 90,
      "confidence_rationale": "Two CQ items directly match the query’s intent. The SPARQL targets participants associated with Clara Schumann, aligning with identifying contemporaneous musicians. The final question is a light paraphrase for clarity.",
      "needs_review": false
    },
    "model": "gpt-5",
    "elapsed_ms": 39076
  },
  {
    "query_id": "meetups__sha256:dbf3641a52ecffab79c6153a63565089555ebdf0713a2bc876df15e668045101",
    "query_label": "meetups-0027",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "What was the composer’s network?",
          "evidence_id": "e41",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": true
        },
        {
          "text": "What was the composer’s network (patrons, institutions …)?",
          "evidence_id": "e21",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": true
        }
      ],
      "nl_question": "Who and which institutions were part of Clara Schumann’s network?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e41",
          "e21"
        ],
        "primary_evidence_id": "e41"
      },
      "confidence": 93,
      "confidence_rationale": "The SPARQL selects entities (with labels) that participated in events involving Clara Schumann, which directly answers the CQ about a composer’s network. Multiple high-priority CQ items exactly match this intent, with one explicitly mentioning patrons and institutions.",
      "needs_review": false
    },
    "model": "gpt-5",
    "elapsed_ms": 37270
  },
  {
    "query_id": "meetups__sha256:a6f0698bc20eadf9e7f0ed3ebe30b9b15d62a5d97917f20d1adac2044395672a",
    "query_label": "meetups-0028",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "Where did musician X and performer Y meet?",
          "evidence_id": "e16",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": false
        },
        {
          "text": "Did musician X and performer Y ever meet? Where, when, and why?",
          "evidence_id": "e3",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": true
        },
        {
          "text": "What places did musician Z visit in his/her career?",
          "evidence_id": "e15",
          "source_type": "cq_item",
          "rank": 3,
          "verbatim": false
        }
      ],
      "nl_question": "Where did musician X and performer Y meet?",
      "nl_question_origin": {
        "mode": "verbatim",
        "evidence_ids": [
          "e16"
        ],
        "primary_evidence_id": "e16"
      },
      "confidence": 80,
      "confidence_rationale": "The SPARQL text describes identifying participants and filtering places to indicate where encounters happened, which aligns closely with the CQ asking where two people met. However, the provided SPARQL is a descriptive fragment rather than an executable query, introducing some ambiguity.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 58292
  },
  {
    "query_id": "meetups__sha256:04586c83afd0b66734da35f4002939036639d30b1a7b7446b3c06486fdaa20ca",
    "query_label": "meetups-0029",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Which subjects are associated with meetups?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No textual evidence was provided, so the question is inferred directly from the SPARQL pattern selecting subjects linked via mtp:hasSubject. The query intent is clear, but confidence is reduced due to lack of supporting evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 10446
  },
  {
    "query_id": "meetups__sha256:aae2da73bb4748bc57c2355af3bd19335298ceaaccf4ea907695bae69b1607fc",
    "query_label": "meetups-0030",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "What meetups did Edward Elgar take part in, and for each, who else participated, where and when did they happen, and for what purpose?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "No supporting natural-language evidence was provided, so the question is derived directly from the SPARQL structure. The query clearly targets Edward Elgar’s meetups and aggregates participants, locations (with coordinates), time spans, and purpose, matching the phrasing.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 25034
  },
  {
    "query_id": "meetups__sha256:c8660d68572c76e27c6d8ef67ae540c297fafa5f351d5eacf1550476f31d3dc2",
    "query_label": "meetups-0031",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Which meetups involve a participant named \"Django,\" and what are their subjects, purposes, locations (with coordinates), other participants, and dates?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 80,
      "confidence_rationale": "The question is derived directly from the SPARQL: it searches for meetups with a participant label matching \"Django\" and returns subject, purpose, locations (with coordinates), other participants, and time spans. No supporting natural-language evidence was provided, so confidence is reduced despite the clear query structure.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 25707
  },
  {
    "query_id": "meetups__sha256:504994c1eb502c592f606ee1c83c82fe21a7e75bb7f7646a04267c6e15d1dc41",
    "query_label": "meetups-0032",
    "kg_id": "meetups",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Which meetups that took place in Vienna are recorded, and what are their subjects, participants, locations (with coordinates), dates, and purposes?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "No natural-language evidence was provided, so the question was generated from the SPARQL structure. The query clearly filters meetups by place label \"Vienna\" and returns the subject, participants, locations with coordinates, time spans, and purpose, matching the question. Lack of supporting evidence and the opaque hasType \"HM\" reduce confidence slightly.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 26436
  },
  {
    "query_id": "musow__sha256:c00189006a424c7340b5855d18bcd43a7ad5c5b9976d5b93ec4cbb1787072e96",
    "query_label": "musow-0001",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many homepage links are recorded in the MUSOW dataset?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No natural-language evidence is provided, so the question is generated directly from the SPARQL, which counts triples where a subject has a foaf:homepage. The wording reflects counting homepage links in the MUSOW graph.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 17835
  },
  {
    "query_id": "musow__sha256:f275ceba436b1864da1c11ccfaff452e13c518411a0630ac5029e10819904dee",
    "query_label": "musow-0002",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources are there for each general resource type?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "No natural-language evidence was provided, so the question is generated directly from the SPARQL, which counts distinct resources grouped by the label of their general resource type. The query intent is clear, but confidence is reduced due to lack of supporting text evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 12604
  },
  {
    "query_id": "musow__sha256:6e882c9fff02c57d41b9d4c68b184a4dd43624532c8bb7c658e9d6bc1e139a1d",
    "query_label": "musow-0003",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources are associated with each subject term?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 80,
      "confidence_rationale": "No natural-language evidence is provided, but the SPARQL clearly counts resources grouped by subject term and its label, making the intent straightforward.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 12107
  },
  {
    "query_id": "musow__sha256:bd5c9af9095e4b3e792522f15f6892bff0e992fc2f932c209498827242766189",
    "query_label": "musow-0004",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW projects are in each size category?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No natural-language evidence was provided, so the question is generated from the SPARQL structure. The query clearly counts projects grouped by the rdfs:label of their dcterms:extent (size), but lack of supporting text lowers confidence slightly.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 14796
  },
  {
    "query_id": "musow__sha256:56e6e4b915af8990cd044eb9017eee761f38c729f8b33a593c2ce79a958ce76b",
    "query_label": "musow-0005",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources fall into each category?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "The SPARQL clearly counts distinct resources grouped by category labels within the MUSOW graph. Confidence is reduced due to the absence of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 8217
  },
  {
    "query_id": "musow__sha256:c9c3c4ffe1a711cc1bf69bde3e987b6e70a29902734e1a9076bf5b6553bbb0e0",
    "query_label": "musow-0006",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources are intended for each audience?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No textual evidence was provided, so the question is generated from the SPARQL structure, which clearly counts distinct resources grouped by audience labels. The intent is straightforward, but lack of supporting evidence reduces confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 10220
  },
  {
    "query_id": "musow__sha256:2a7b97a66f3f11c08cc8186480a5be1db4e800330bfa7373cd252ab3e04527b6",
    "query_label": "musow-0007",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources aimed at researchers are in each category?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 76,
      "confidence_rationale": "No natural-language evidence is provided, so the question is generated from the SPARQL. The query clearly counts distinct resources grouped by category where the audience label is \"researchers\" within the MUSOW graph.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 12490
  },
  {
    "query_id": "musow__sha256:56adfe7d19ee113566defeef4a1e11d0f44f288252dea8ef126c7be00a2b5c83",
    "query_label": "musow-0008",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources are intended for both researchers and performers?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "The question is derived directly from the SPARQL, which filters resources by audience labels 'researchers' and 'performers' and returns a distinct count. Confidence is reduced due to the absence of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 13231
  },
  {
    "query_id": "musow__sha256:8d919a7ed370f6daf21058e43e873458a28e9e69c943ba86cf22db4f81bbdf76",
    "query_label": "musow-0009",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources are intended for audiences other than researchers?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "The SPARQL counts distinct resources whose audience label is not 'researchers', clearly indicating a single numeric result. Confidence is moderated due to the absence of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 9757
  },
  {
    "query_id": "musow__sha256:af801876333b38b8d45d61ff2c0c6a0169770fbf9fa4209972f6bba60431ab06",
    "query_label": "musow-0010",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources are tagged with each catalogue?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "The SPARQL groups catalogues labeled as type \"Catalogue\" and counts resources linked via fabio:hasSubjectTerm, clearly indicating counts per catalogue. Confidence is moderated due to the absence of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 19425
  },
  {
    "query_id": "musow__sha256:87255d1439bbd9e1b789f4b702e9712ce3db59e9abba527ed3ba0f702d763624",
    "query_label": "musow-0011",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For MUSOW resources linked to catalogues, how many fall under each category?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 71,
      "confidence_rationale": "No natural-language evidence is provided, so the question is generated from the SPARQL structure. The query counts distinct resources grouped by category labels, filtered to resources associated with catalogue subject terms, which the question captures.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 24796
  },
  {
    "query_id": "musow__sha256:1d515ff2fa6ccee2b3011417e0a24c91262c366f64e031550e2004c3b9f489eb",
    "query_label": "musow-0012",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For MUSOW resources tagged with a Catalogue subject term, how many are there for each general resource type?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "No textual evidence was provided, but the SPARQL clearly counts distinct resources grouped by their general resource type, restricted to those linked via hasSubjectTerm to items whose type label is \"Catalogue.\"",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 18213
  },
  {
    "query_id": "musow__sha256:ba9e3109ef7cecd1fd910850d786109adaaceb701ae6acb56430f96054d10e2f",
    "query_label": "musow-0013",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources linked to catalogues are there for each audience?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 78,
      "confidence_rationale": "No natural-language evidence was provided, so the question is generated from the SPARQL. The query clearly counts distinct resources grouped by audience labels, restricted to resources associated with catalogues.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 16811
  },
  {
    "query_id": "musow__sha256:c238650278b8eea9849dce79b7e1c90e8404f3fc2030e4e86d50c9b4048f7837",
    "query_label": "musow-0014",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For each extent, how many MUSOW resources are aimed at researchers, performers, and scholars?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 74,
      "confidence_rationale": "No textual evidence is provided, so the question is generated directly from the SPARQL. The query clearly counts distinct resources grouped by extent where the audience includes researchers, performers, and scholars.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 14098
  },
  {
    "query_id": "musow__sha256:0b5d731fc348f9b4777f1d7999f219ffc556557ba68622893ebfb035bb3c57bc",
    "query_label": "musow-0015",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For each MUSOW catalogue, how many related resources are associated with it?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "The SPARQL groups catalogue-type resources by label and counts distinct skos:related links, which clearly supports the question. Confidence is reduced due to the absence of natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 9572
  },
  {
    "query_id": "musow__sha256:9923b29b7cb84cc68d458aa6c654a2d272af0ec9a73b093f61a4b33d06b42881",
    "query_label": "musow-0016",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources are of type Repository or Digital Library?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "The SPARQL clearly counts distinct resources whose type label is either \"Repository\" or \"Digital Library\". However, no supporting natural-language evidence was provided, so the question is generated from query structure.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 10513
  },
  {
    "query_id": "musow__sha256:3df306e046488ec91a6a5646924d3cef32198ad7219639314dd4a8e4598425c0",
    "query_label": "musow-0017",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources that are Repositories or Digital Libraries fall under each extent?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 68,
      "confidence_rationale": "The question is derived directly from the SPARQL structure: counting distinct resources grouped by extent label and filtered to resource types labeled \"Repository\" or \"Digital Library.\" Confidence is limited by the absence of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 20165
  },
  {
    "query_id": "musow__sha256:43248450b08bbafe855d33c2248c870db8b7383972b0d3f72de106e6dffa552e",
    "query_label": "musow-0018",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources of type Repository or Digital Library are there for each format?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No supporting natural-language evidence was provided, so the question is derived directly from the SPARQL structure. The query clearly counts distinct resources grouped by format and filters for types labeled \"Repository\" or \"Digital Library\", but lack of evidence lowers confidence slightly.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 13310
  },
  {
    "query_id": "musow__sha256:9b23c2fd05a6c98e670d5c47283d52f58ed0c89a4d14e464cfab404f65da44f9",
    "query_label": "musow-0019",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources of type Repository or Digital Library are there for each extent and format?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "The question is derived directly from the SPARQL: it counts distinct resources grouped by extent and format and filters resource types to \"Repository\" or \"Digital Library.\" Confidence is moderated due to the absence of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 14035
  },
  {
    "query_id": "musow__sha256:acd9a72c38c1981588b4a44c63c850642da2c2bfc030fa810d58d9c910425cb6",
    "query_label": "musow-0020",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many interoperable repositories or digital libraries are in MUSOW?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "No textual evidence was provided, so the question is generated from the SPARQL structure. The query clearly counts distinct resources that are tagged as interoperable and whose type label is either Repository or Digital Library, making the intent straightforward despite the lack of supporting evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 16717
  },
  {
    "query_id": "musow__sha256:12880099b5907b9f4902b89188b05b81e0c89ba7d5be82dcc9b77d0e930b00b8",
    "query_label": "musow-0021",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources that are repositories or digital libraries are in any of these formats: PDF, JPG, TIFF, IIIF, GIF, PNG, or DjVu?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 68,
      "confidence_rationale": "No natural-language evidence was provided, so the question is generated directly from the SPARQL. The query clearly counts distinct resources labeled as \"Repository\" or \"Digital Library\" whose format matches one of the listed formats, but the lack of supporting evidence lowers confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 15725
  },
  {
    "query_id": "musow__sha256:108e2a8571f57ea1290a4d12fcb754093d645c8ef76f2863baffe7ae69e6900d",
    "query_label": "musow-0022",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources are repositories or digital libraries and available in one of these formats: MIDI, MP3, audio, video, Finale, Sibelius, or FLAC?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "No supporting natural-language evidence is provided, but the SPARQL clearly counts distinct resources filtered to type labels “Repository” or “Digital Library” and to a specific set of formats. The question directly mirrors these constraints.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 15510
  },
  {
    "query_id": "musow__sha256:ab152cb9dc76ecb0b1bb678401f2daa42cb9a04530fc6771d4c1db1cfe055052",
    "query_label": "musow-0023",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources of type Repository or Digital Library are available in any of these formats: MusicXML, XML, RDF, MEI/XML, CAP/XML, Humdrum, Kern, LilyPond, MuseData, MuseScore, MYR, Noteworthy, PY, RAM, or MU2?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No textual evidence was provided, so the question is generated directly from the SPARQL structure. The query clearly counts distinct resources filtered to Repository or Digital Library types and a fixed list of formats, which the question captures.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 16095
  },
  {
    "query_id": "musow__sha256:2acc997a5d898cae07efcb08fb6899039cbc6c31772b3da2ba6d41d1cf88118f",
    "query_label": "musow-0024",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For each scope, how many MUSOW resources are repositories or digital libraries?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 68,
      "confidence_rationale": "The SPARQL aggregates counts of distinct resources grouped by scope, filtered to resources labeled as 'Repository' or 'Digital Library'. With no supporting natural-language evidence, the question is inferred directly from the query structure, lowering confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 13584
  },
  {
    "query_id": "musow__sha256:07673a60d8bffe60dcb5dc78933f2afbc703cc59a41a4b984f7538eb5608b00c",
    "query_label": "musow-0025",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources of type Repository or Digital Library are there for each extent and scope?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No textual evidence was provided, so the question is generated from the SPARQL structure. The query clearly counts distinct resources grouped by extent and scope, limited to resource types labeled \"Repository\" or \"Digital Library.\"",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 11660
  },
  {
    "query_id": "musow__sha256:d8c2aa0ca50ea824a77f8c000ec5c6755b6b84a04ac7a8b33adbd65c0aa8206d",
    "query_label": "musow-0026",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Among MUSOW resources labeled as Repository or Digital Library, how many are there for each scope and format?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 68,
      "confidence_rationale": "No textual evidence is provided, so the question is generated from the SPARQL structure. The query clearly counts distinct resources grouped by scope and format, restricted to types labeled \"Repository\" or \"Digital Library.\"",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 11670
  },
  {
    "query_id": "musow__sha256:69e3d43f668486f4d55097fe94df874c1b1e4c8571ec875084b94dfa2b896a79",
    "query_label": "musow-0027",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For repositories and digital libraries in MUSOW that have the 'symbolic machine-readable' feature, how many resources are there for each scope?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "No textual evidence is provided, so the question is generated from the SPARQL structure. The query clearly counts distinct resources with the 'symbolic machine-readable' feature, restricted to Repository or Digital Library types, grouped by scope.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 12844
  },
  {
    "query_id": "musow__sha256:a984f9b3bc006a3660301ce948c0e408312cc68095afaa8fe12912d0de7153cd",
    "query_label": "musow-0028",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For MUSOW repositories and digital libraries with the 'symbolic-machine-readable' feature, how many resources are there for each extent value?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "The question is generated directly from the SPARQL: it groups by extent label and counts distinct resources filtered to repositories or digital libraries with the symbolic-machine-readable feature. Confidence is reduced due to the absence of supporting natural-language evidence and potential ambiguity around the meaning of 'extent'.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 16961
  },
  {
    "query_id": "musow__sha256:ac31b80982ba2cef1b1e0e2369d02a3af1993552eb38fdb1f8d56c810e8d105e",
    "query_label": "musow-0029",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW repository or digital library resources are associated with each feature?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No natural-language evidence is provided, so the question is generated from the SPARQL structure. The query groups resources by feature label and counts distinct resources where the resource type label is \"Repository\" or \"Digital Library,\" which aligns with the phrasing.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 16236
  },
  {
    "query_id": "musow__sha256:698148bfdbee6148629664c7a1f85ff8668c5ee2048515a33de26d47fe9c2c91",
    "query_label": "musow-0030",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For MUSOW resources classified as Repository or Digital Library, how many are there in each category?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 68,
      "confidence_rationale": "The question is directly inferred from the SPARQL: it counts distinct resources grouped by category labels, restricted to resource types labeled \"Repository\" or \"Digital Library\" within the MUSOW context. Confidence is moderated due to the absence of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 12061
  },
  {
    "query_id": "musow__sha256:f2a95d901d26b9b0585dbc2bb225fc1741079a9e7fd25d1e2adc8cccb939bdc3",
    "query_label": "musow-0031",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many free-access MUSOW resources are repositories or digital libraries?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No natural-language evidence is provided, so the question is generated directly from the SPARQL. The query clearly counts distinct resources with access type \"Free\" whose type label is \"Repository\" or \"Digital Library\" in the MUSOW graph.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 8157
  },
  {
    "query_id": "musow__sha256:f189f50292e28375b06fa3616521f5bd7925354cd4455af25a538f8b3a82939e",
    "query_label": "musow-0032",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For MUSOW repositories and digital libraries, how many resources use each license?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No textual evidence was provided, so the question is generated directly from the SPARQL structure. The query clearly counts distinct resources grouped by license label, filtered to resource types labeled \"Repository\" or \"Digital Library,\" which the question reflects.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 13299
  },
  {
    "query_id": "musow__sha256:5891eaf420698fcc8ae09c7d69346b0611b25ad46d1da52f1fa880b245daeffb",
    "query_label": "musow-0033",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources are there for each audience, considering only those whose type is Repository or Digital Library?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "The question is derived directly from the SPARQL, which counts distinct resources grouped by audience labels and filters for resource types labeled \"Repository\" or \"Digital Library.\" Confidence is moderated due to the absence of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 11561
  },
  {
    "query_id": "musow__sha256:018f09e58a8b9d6b39f54088357e9f9e32cac9eb5fef5ab8ef3f2d40ae3b8c71",
    "query_label": "musow-0034",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources of type Repository or Digital Library are there for each purpose?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "The question is derived directly from the SPARQL, which groups resources by purpose and counts distinct resources, filtered to types 'Repository' or 'Digital Library'. Confidence is moderated due to the absence of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 12005
  },
  {
    "query_id": "musow__sha256:689a12a61ff05de2ebe68e3e39fe9f6424f7f7635143adf7693ebbaf22e38a0d",
    "query_label": "musow-0035",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources that are repositories or digital libraries are intended for amateurs or listeners?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "No textual evidence is provided, so the question is generated directly from the SPARQL, which clearly counts distinct resources of type Repository or Digital Library with audience labels 'amateurs' or 'listeners'. The intent is unambiguous, but confidence is reduced due to lack of supporting evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 12726
  },
  {
    "query_id": "musow__sha256:8f9d8d41ef245422c2dd82887b2da67f938bcfe2dbc401b313b8bc4c5ce3e6d8",
    "query_label": "musow-0036",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For each MUSOW resource of type Repository or Digital Library, how many other resources are related to it?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 71,
      "confidence_rationale": "The SPARQL clearly counts distinct related resources for each resource labeled as a Repository or Digital Library. Confidence is reduced due to the absence of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 19934
  },
  {
    "query_id": "musow__sha256:f6267dd43bae70fabe1b3fee2d330f0da503024ee950ee677ead3d17fdbe0644",
    "query_label": "musow-0037",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources are datasets?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "The SPARQL clearly counts distinct resources whose general resource type label is 'Dataset' in the MUSOW graph. Confidence is tempered by the absence of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 6200
  },
  {
    "query_id": "musow__sha256:97f982ba77cce8d8357cef4369859b0a614e8397cebf523549f2fc0ab7680e96",
    "query_label": "musow-0038",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many datasets are there for each format in MUSOW?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No textual evidence was provided, but the SPARQL clearly counts distinct resources labeled as 'Dataset' grouped by their format. The question reflects this aggregation accurately.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 14821
  },
  {
    "query_id": "musow__sha256:1f36ff38afc27d2036ac081fa296061be35381d0ba4575398ac8c5e2cd8d4550",
    "query_label": "musow-0039",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW datasets are there for each extent and format?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No evidence was provided, so the question is generated from the SPARQL. The query clearly counts distinct resources of type 'Dataset' grouped by extent and format, which the question reflects. Confidence is moderate due to lack of corroborating text evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 14295
  },
  {
    "query_id": "musow__sha256:64ef52f5dd643acc9133332af9cec3a9bd31a37206f146d93e35c1ea458adf82",
    "query_label": "musow-0040",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW datasets are available for each scope?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 74,
      "confidence_rationale": "No natural-language evidence was provided, so the question is generated from the SPARQL structure. The query clearly counts distinct resources of type 'Dataset' grouped by scope labels, but lack of corroborating evidence reduces confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 11593
  },
  {
    "query_id": "musow__sha256:7cb96090f2a14e36d23690894add0d30f68172ed6b27629ad84868499a4f5a1c",
    "query_label": "musow-0041",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For each primary topic, how many MUSOW datasets are there?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 68,
      "confidence_rationale": "The SPARQL groups by feature labels linked via foaf:primaryTopic and counts distinct resources, while filtering to those whose resource type label is 'Dataset'. With no supporting evidence text, the question is inferred directly from the query structure.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 12430
  },
  {
    "query_id": "musow__sha256:fa9e109dd493f91dc76cb9da37e94fdd7fb66ae4cec7b4bdead2000f0a54ddba",
    "query_label": "musow-0042",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW datasets are in each category?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No natural-language evidence was provided, so the question is inferred directly from the SPARQL, which groups datasets by category and counts resources. The intent is clear, but lack of supporting text and ambiguity about the exact meaning of \"category\" reduce confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 12808
  },
  {
    "query_id": "musow__sha256:18e011c0d7e8d8f0ccd66b69c09baee309e82be898af78bc2753e1226ffdbd28",
    "query_label": "musow-0043",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For MUSOW datasets, how many resources are there for each feature list?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No natural-language evidence was provided, so the question is derived directly from the SPARQL, which groups dataset-type resources by featureList label and counts them. The query structure is clear, but lack of corroborating evidence lowers confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 11311
  },
  {
    "query_id": "musow__sha256:7bbb93486d78a4db6b148d203699f7e9f95e2c3b9faf49b93ef71b5612704e34",
    "query_label": "musow-0044",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For each task, how many MUSOW datasets are there?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "No natural-language evidence was provided, so the question is generated from the SPARQL structure. The query groups datasets by task label and counts distinct resources, which aligns directly with the phrasing.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 10525
  },
  {
    "query_id": "musow__sha256:fdff1d2dccddad7066ed46c86ef90f8d928154164f974f78e68ac39fd97d0d30",
    "query_label": "musow-0045",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW datasets are there for each license?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "No supporting evidence was provided, but the SPARQL clearly counts distinct resources labeled as 'Dataset' grouped by their license labels. The intent to report counts per license is unambiguous.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 9123
  },
  {
    "query_id": "musow__sha256:f5a9b043db7a5241729a5497af8c29d55e51fe46e1c70fb0609682a12dedd902",
    "query_label": "musow-0046",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW datasets are there for each purpose?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "No evidence text was provided, so the question is generated directly from the SPARQL, which clearly counts distinct resources labeled as 'Dataset' grouped by their purpose labels. The intent appears unambiguous, but confidence is reduced due to lack of supporting evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 12190
  },
  {
    "query_id": "musow__sha256:235b981abbd5adbe8a846c82756fd8e256c2ff17cca2b0c3bd70a9eeaf86afd5",
    "query_label": "musow-0047",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW datasets are aimed at amateurs or listeners?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "No natural-language evidence is provided, so the question is generated from the SPARQL. The query clearly counts distinct resources with type label 'Dataset' and audience labels 'amateurs' or 'listeners', but lack of supporting text reduces confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 12930
  },
  {
    "query_id": "musow__sha256:787cf500cd5bc521f7a70db1f9d8072d6e7b8c6579d8ab7a45a87db8f0dc2411",
    "query_label": "musow-0048",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For each MUSOW dataset, how many other resources are related to it?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "The question is derived directly from the SPARQL, which filters resources labeled as 'Dataset' and counts distinct resources connected via a related link. Confidence is reduced due to the absence of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 22474
  },
  {
    "query_id": "musow__sha256:a129d38bc3f11422ddc96fe785cf6763dbceac69c69652c1ffe0dfbae680c2c6",
    "query_label": "musow-0049",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For MUSOW datasets in RDF format, how many fall into each category?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "No supporting evidence is provided, but the SPARQL clearly groups by category label and counts distinct resources filtered to type 'Dataset' and format 'RDF' in the MUSOW graph.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 19525
  },
  {
    "query_id": "musow__sha256:e3bca390060b090b0e1f1392b120316a1bf477fd50a38f9b2c75eb0d80e33f0c",
    "query_label": "musow-0050",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW datasets in RDF format have each feature?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No textual evidence is provided, so the question is generated from the SPARQL. The query clearly filters resources labeled as 'Dataset' with format 'RDF', groups by featureList label, and counts distinct resources, which the question reflects.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 19076
  },
  {
    "query_id": "musow__sha256:67c424b1524844c11a47a9938abafce415bd67e62917943023deca19beb0c19f",
    "query_label": "musow-0051",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For MUSOW datasets in RDF format, how many resources are associated with each task?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "No natural-language evidence is provided, so the question is generated directly from the SPARQL structure. The query clearly counts distinct resources grouped by task labels, filtered to resources labeled as 'Dataset' and format 'RDF' within the MUSOW context.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 16672
  },
  {
    "query_id": "musow__sha256:71f9eda718d661ba255738866d9440b439048c6e9f4aa12525bcdddb4ae8a479",
    "query_label": "musow-0052",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW dataset resources in RDF format are there for each category?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "The question is derived directly from the SPARQL: it counts distinct resources grouped by category label, filtered to resources labeled as 'Dataset' and with format 'RDF'. No supporting text evidence was provided, so confidence is moderate.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 16309
  },
  {
    "query_id": "musow__sha256:9545c7530923f008e654885556ae722c3dc634f1d8f776cce756f79504c95c4b",
    "query_label": "musow-0053",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW RDF datasets are there for each feature list label?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 69,
      "confidence_rationale": "No textual evidence was provided, so the question is generated directly from the SPARQL structure. The query clearly counts distinct resources of type label 'Dataset' with format label 'RDF', grouped by featureList label, but lack of supporting evidence lowers confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 21220
  },
  {
    "query_id": "musow__sha256:3c2444f7be9392d498f25981120db524c5da90c83fa9cc51e6000c6c0d8b671a",
    "query_label": "musow-0054",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW datasets in RDF format are there for each task?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "No textual evidence was provided, so the question is generated from the SPARQL. The query filters to resources labeled as 'Dataset' with format label 'RDF', groups by task label, and counts distinct resources, which the question reflects.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 19828
  },
  {
    "query_id": "musow__sha256:31334577eecf0a11186905336b7cfcaaa93ecfab2d6569eb8c3c850ae062ad8b",
    "query_label": "musow-0055",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many resources in MUSOW are classified as 'Digital edition'?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 68,
      "confidence_rationale": "The SPARQL clearly counts distinct resources whose resource type label is 'Digital edition'. However, there is no supporting natural-language evidence, so the question is generated from query structure and confidence is reduced.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 14958
  },
  {
    "query_id": "musow__sha256:ca9a11d49a0629969b24848061a086c1018f85dc14ab4e3f23b57b0cdef4fbbe",
    "query_label": "musow-0056",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW 'Digital edition' resources are there for each format?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No natural-language evidence is provided, so the question is generated directly from the SPARQL, which clearly counts distinct resources filtered to type 'Digital edition' and groups them by format. Confidence is moderate due to the lack of corroborating evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 12496
  },
  {
    "query_id": "musow__sha256:c393696633b42b904beafc35dd75d2651e6f88cbeeb5384c67f59f65a6934d35",
    "query_label": "musow-0057",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources of type Digital edition are there for each scope?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No textual evidence is provided, so the question is generated from the SPARQL: it counts distinct resources grouped by scope labels where the resource type label is 'Digital edition'. The structure is clear, but confidence is reduced due to lack of supporting evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 17768
  },
  {
    "query_id": "musow__sha256:333c6ab20c48f75085f6c0063ad7d4af0f6d4c79892f660043e642811a3d688b",
    "query_label": "musow-0058",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW digital edition resources are there for each extent value?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No textual evidence is provided, so the question is generated from the SPARQL structure. The query clearly counts distinct resources labeled as 'Digital edition' grouped by the rdfs:label of dcterms:extent, which the question reflects.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 12774
  },
  {
    "query_id": "musow__sha256:a39c5d7b90457ae5ed7462583488e8d7def5b3ce411f3a7e60391617955fcf68",
    "query_label": "musow-0059",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources of type Digital edition have the playable feature?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "No textual evidence is provided, but the SPARQL clearly counts distinct resources whose general resource type label is 'Digital edition' and whose feature list includes 'playable'. The intent is unambiguous despite lacking supporting evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 9903
  },
  {
    "query_id": "musow__sha256:599ce8a4c361d34d1cbf1d861a79df62386d53755f4acd3b6653de272568317c",
    "query_label": "musow-0060",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources of type “Digital edition” are there for each primary topic?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "The question is derived directly from the SPARQL structure: it counts distinct resources labeled as the general resource type “Digital edition,” grouped by the label of each resource’s foaf:primaryTopic. No textual evidence was provided to confirm terminology, lowering confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 12220
  },
  {
    "query_id": "musow__sha256:1ad8b854269dd6c557e2845095a9259ddb0eb7fd6dabf6af1c73ec5c83979f8a",
    "query_label": "musow-0061",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources classified as 'Digital edition' are there in each category?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "No textual evidence was provided, so the question is generated directly from the SPARQL structure. The query clearly counts distinct resources with type label 'Digital edition' grouped by category, but the lack of supporting evidence lowers confidence slightly.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 13922
  },
  {
    "query_id": "musow__sha256:dc7575dea3c7cfb351038b14e79c9b2ae4a071971f51c11468903b02ef8a389c",
    "query_label": "musow-0062",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW Digital edition resources are there for each feature list label?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No textual evidence was provided, so the question is derived directly from the SPARQL structure. The query clearly counts distinct resources labeled as 'Digital edition' and groups the counts by the schema.org featureList label, but absence of supporting evidence lowers confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 17592
  },
  {
    "query_id": "musow__sha256:e93ad90507b8593657646a5f2162dd97ef01078940b491dac7e417e4c169c07f",
    "query_label": "musow-0063",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For MUSOW resources classified as Digital edition, how many resources fall under each task?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 68,
      "confidence_rationale": "The SPARQL clearly filters resources to those whose type label is 'Digital edition', groups by task label, and counts distinct resources per task. With no supporting evidence text, the question is generated from the query structure, so confidence is moderate.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 13052
  },
  {
    "query_id": "musow__sha256:c4ae6d7da48116c4b4b7d26eb3b49c2b9429de8420129ea03d24003a3c01ad62",
    "query_label": "musow-0064",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For each MUSOW \"Digital edition\" resource, how many related resources link to it?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "The question is directly derived from the SPARQL: it filters resources by type label 'Digital edition', groups by the resource label, and counts distinct incoming related resources. Confidence is moderate due to the absence of supporting NL evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 17798
  },
  {
    "query_id": "musow__sha256:3973d82bbe31935841ef2497dd6cdf83f9b1223096151d56ed4f5453b0eaa5f8",
    "query_label": "musow-0065",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "What related resources are linked to MUSOW 'Digital edition' items, and how many times does each appear?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "With no textual evidence provided, the question is generated from the SPARQL structure. The query filters resources to those labeled 'Digital edition', finds their SKOS-related resources, groups by the related resource label, and counts distinct related resources, which the question reflects.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 18221
  },
  {
    "query_id": "musow__sha256:fffcd5e65f0dfe18b48ca67d1594c287f6a0c7396207cb09f70c32fe440869f9",
    "query_label": "musow-0066",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Which resources are linked to digital editions, and what tasks are those digital editions associated with?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "The SPARQL clearly selects labels of resources related via skos:related to items labeled as the resource type 'Digital edition' and returns their associated task labels. The question reflects both outputs, but confidence is tempered due to the absence of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 15290
  },
  {
    "query_id": "musow__sha256:30b938e66f831a367149106c66f7067c2fd05000133c21e68be655ac796fb0d7",
    "query_label": "musow-0067",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources are classified as Software or Service?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No natural-language evidence is provided. The SPARQL clearly counts distinct resources whose general resource type label is either 'Software' or 'Service', so the question is directly derived from the query structure.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 10022
  },
  {
    "query_id": "musow__sha256:45820271c928be86e9394d8ebff319945cb1d582326b71502acf283b54e0ec03",
    "query_label": "musow-0068",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources of type 'Software' or 'Service' are there for each format?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 73,
      "confidence_rationale": "The question is derived directly from the SPARQL structure: it counts distinct resources grouped by format and filters resource types to Software or Service. Confidence is slightly reduced due to the absence of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 11329
  },
  {
    "query_id": "musow__sha256:e51872c9e093ad085674fca3845ac5559fc3db5021339490ea59c3f7113afb1e",
    "query_label": "musow-0069",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW Service or Software resources are associated with each task?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "The SPARQL clearly groups by task label and counts distinct resources filtered to types 'Service' or 'Software'. Confidence is moderated due to the absence of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 12462
  },
  {
    "query_id": "musow__sha256:506f1005f383e0b38b411b68e28df3bf1bd5586100b1c46eed81b3eb7d32e4b3",
    "query_label": "musow-0070",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources of type Service or Software are associated with each feature?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No textual evidence is provided, so the question is derived directly from the SPARQL structure, which groups by feature labels and counts distinct resources filtered to types 'Service' and 'Software'. The intent is clear but lacks supporting evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 11896
  },
  {
    "query_id": "musow__sha256:6ca4e7d51cbbbd6e9f3207ce9e3dd320a72e00a16f53f50bec3016a87cc96a56",
    "query_label": "musow-0071",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For MUSOW resources whose general type is Service or Software, how many fall into each category?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 68,
      "confidence_rationale": "No natural-language evidence is provided, so the question is generated directly from the SPARQL structure. The query clearly counts distinct resources grouped by category for resource types labeled Service or Software, but lack of supporting text lowers confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 12971
  },
  {
    "query_id": "musow__sha256:ae2d1ddd8a47b011fa64c88415ebdfe6b5a77d8ae8ac20fa3911669c208bbcf3",
    "query_label": "musow-0072",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For each related resource, how many MUSOW resources of type 'Service' or 'Software' are linked to it?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 68,
      "confidence_rationale": "No natural-language evidence is provided, so the question is generated directly from the SPARQL structure. The query clearly counts, for each related resource label, how many distinct Service/Software resources are related to it, but the absence of supporting text reduces confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 20178
  },
  {
    "query_id": "musow__sha256:2e784aefb332fd5cec99127ba41e68874e1120b2931b13211fa2818ec1afdbef",
    "query_label": "musow-0073",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For each MUSOW resource of type Service or Software, which related resources (by label) are associated with it, and how many of each are there?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 68,
      "confidence_rationale": "No textual evidence was provided, so the question is derived directly from the SPARQL structure: it selects labels of Service/Software resources, labels of resources related to them, and counts distinct related resources per label. Minor ambiguity remains about the directionality of the SKOS relation.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 20926
  },
  {
    "query_id": "musow__sha256:fa4b0c1cd446f3a00c23b75fcb8a7dd5ea491b0321f5976dcf3a052e14498803",
    "query_label": "musow-0074",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources are classified as Ontology or Schema?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "The question is derived directly from the SPARQL, which counts distinct resources whose general resource type label is 'Ontology' or 'Schema'. Confidence is reduced due to the lack of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 11171
  },
  {
    "query_id": "musow__sha256:644203df95be50b109680eac96b82b7358fdc1356d8fa1c8c92201bac84ce051",
    "query_label": "musow-0075",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources labeled as Ontology or Schema are in each category?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No text evidence was provided, so the question is derived directly from the SPARQL: it groups by category label and counts distinct resources filtered to the types 'Ontology' or 'Schema'. The intent is clear, but absence of supporting evidence lowers confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 16082
  },
  {
    "query_id": "musow__sha256:b10dfd3db1f2f9f463cbeb57aa9b7d84f04a942f13de750b2309efa0558a2403",
    "query_label": "musow-0076",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For MUSOW resources of type Ontology or Schema, how many resources are associated with each primary topic?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "The question is generated directly from the SPARQL: it groups resources by the label of their foaf:primaryTopic and counts them, restricted to resource types labeled 'Ontology' or 'Schema'. Confidence is moderated due to the absence of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 16091
  },
  {
    "query_id": "musow__sha256:2eb838182d7891d78b781accbbb37928619cf4254157eb608510b9feff9772a4",
    "query_label": "musow-0077",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For each MUSOW Schema or Ontology, which other resources are related to it, and how many distinct related resources are there?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "The question is generated directly from the SPARQL structure: it selects resources typed as Schema or Ontology, lists related resources, and counts distinct related resources. Confidence is moderate due to absence of supporting natural-language evidence and a slightly unusual grouping that may affect how the count is interpreted.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 27844
  },
  {
    "query_id": "musow__sha256:ab6ec0c5249e4ab57bd94247d701ac227255138e2f7d714ed682334881c5940a",
    "query_label": "musow-0078",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources are there for each format?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "No evidence text was provided, so the question is inferred from the SPARQL, which clearly counts distinct resources grouped by format labels. The lack of supporting evidence lowers confidence despite the straightforward query structure.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 15865
  },
  {
    "query_id": "musow__sha256:127ff38ca0e2f1b240c5c13d862f0f20c80d55f982a262d258b6ac88089f327c",
    "query_label": "musow-0079",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many interoperable MUSOW resources are there for each format?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "The question is generated directly from the SPARQL: it filters resources with the 'interoperable' feature, groups by format label, and counts distinct resources. Confidence is reduced due to the absence of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 11552
  },
  {
    "query_id": "musow__sha256:00c9231e4a5b8854b0d15fdd7373b25f68da10f55bba5c658ec7c2837a04144a",
    "query_label": "musow-0080",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources are there for each extent and format?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "The SPARQL groups by extent and format labels and counts distinct resources, clearly indicating a count per extent–format combination. Confidence is moderated due to the absence of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 6801
  },
  {
    "query_id": "musow__sha256:e8590074572a73571fc644518df535582dbe3c186cad5931e014f65e329737f3",
    "query_label": "musow-0081",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For each feature and format, how many MUSOW resources are there?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No textual evidence is provided, so the question is derived from the SPARQL structure. The query groups by feature and format labels and counts distinct resources, which the question captures clearly.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 12805
  },
  {
    "query_id": "musow__sha256:1051d42c1edcd27613ea78e6ff0833c53e85681a14e71e12bb51b6ee4d2dabaf",
    "query_label": "musow-0082",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources are there for each format and task?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 68,
      "confidence_rationale": "The question is derived directly from the SPARQL, which counts resources grouped by both format and task labels. Confidence is limited by the absence of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 10307
  },
  {
    "query_id": "musow__sha256:011f651dcb9c242145a9ab81e6f1cb3b9ed2b4bbfe669513a9ed13fffb9d4786",
    "query_label": "musow-0083",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources have the 'symbolic machine-readable' feature?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "No natural-language evidence was provided, so the question is generated directly from the SPARQL, which clearly counts distinct resources with the feature 'symbolic machine-readable' in MUSOW. Lack of supporting text lowers confidence slightly.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 10473
  },
  {
    "query_id": "musow__sha256:62794758bdba6bd7d72bbb2bb201534e3164099e1bb55e1f057be934d699680f",
    "query_label": "musow-0084",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources with the symbolic machine-readable feature are there for each extent value?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "The question is directly inferred from the SPARQL, which filters MUSOW resources by the symbolic machine-readable feature, groups them by extent label, and counts them. Confidence is reduced due to the absence of textual evidence clarifying the meaning of 'extent.'",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 8972
  },
  {
    "query_id": "musow__sha256:c15290b3f628e068fadb35d24a5a492cfdd6f35509fa6b93c8f0950d6b4ec13a",
    "query_label": "musow-0085",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources with the symbolic machine-readable feature are there for each general resource type?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "With no supporting evidence, the question is generated from the SPARQL structure. The query clearly counts distinct resources that have the 'symbolic-machine-readable' feature, grouped by general resource type label.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 15230
  },
  {
    "query_id": "musow__sha256:90a5ef927bc77f220b937879e2eff7f37fa5ff738c01515c0167e050c9b55f29",
    "query_label": "musow-0086",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For each general resource type in MUSOW, how many resources are symbolic machine-readable and how many resources are there in total?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "The question is derived directly from the SPARQL: it groups by resource type label and returns two counts—symbolic machine-readable resources and total resources per type. Confidence is reduced due to the absence of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 10256
  },
  {
    "query_id": "musow__sha256:808615f37f654a1b35278f12da96d25c0aae2676efc2fa4737312a23f3523294",
    "query_label": "musow-0087",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources are associated with each feature (primary topic)?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No evidence snippets were provided, so the question is derived directly from the SPARQL, which counts distinct resources grouped by the label of their foaf:primaryTopic (feature). The intent is clear, but confidence is reduced due to lack of corroborating text evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 12796
  },
  {
    "query_id": "musow__sha256:1e25c81942b6507194a963f7de60e155d4e7ac67c883a70ac733f0c8d6c72e13",
    "query_label": "musow-0088",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources are there for each combination of primary topic (feature) and extent?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No textual evidence is provided, so the question is generated directly from the SPARQL, which counts distinct resources grouped by featureLabel (primary topic) and extentLabel. Minor ambiguity remains about the precise meaning of \"extent\" and \"feature\" in the dataset.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 16904
  },
  {
    "query_id": "musow__sha256:a93b530c4cc2afb7492339245f44b21bc9cc93fb1f2548b431e9a92e52452adf",
    "query_label": "musow-0089",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources fall under each category?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "No natural-language evidence is provided, so the question is generated from the SPARQL structure, which counts distinct resources grouped by a category label within the MUSOW context. The intent is clear, but confidence is reduced due to the lack of supporting text evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 12712
  },
  {
    "query_id": "musow__sha256:1b86168b0815e0a32a92cbfe98df4aadcd972ab9429a430e2ae1c752d7cfc53e",
    "query_label": "musow-0090",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources are there for each category and primary topic?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "The SPARQL groups resources by the label of their DBpedia category and the label of their primary topic, counting distinct resources per pair. No supporting natural-language evidence was provided, so the question is inferred directly from the query.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 20840
  },
  {
    "query_id": "musow__sha256:3a0934922d6614fbead51b0b8f176251b6af2b9a475c19f686c99a3b5f664b65",
    "query_label": "musow-0091",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "How many MUSOW resources are associated with each task and feature?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 74,
      "confidence_rationale": "No textual evidence is provided, but the SPARQL clearly counts distinct resources grouped by task and feature labels. Confidence is moderated due to the lack of corroborating evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 15239
  },
  {
    "query_id": "musow__sha256:5f359ec0c17e5b1a2ea4ea2aa5b8ae08a378ef4754be4b004aa7ad217b68245c",
    "query_label": "musow-0092",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Which MUSOW resources have a license, and what are their webpage, label, category, audience, genre, type, and license label?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "The question is derived directly from the SPARQL: it selects resources that have schema:license and optionally returns webpage, label, category, audience, genre, type/additionalType, and the license label. Confidence is reduced due to lack of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 12719
  },
  {
    "query_id": "musow__sha256:c3f0caae6a28c630069cc42fa8f462f08fd406d65209baaf89b721db71755048",
    "query_label": "musow-0093",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For each resource, indicate whether the copyright, licence, and terms fields are provided.",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 73,
      "confidence_rationale": "No textual evidence was provided, so the question is derived from the SPARQL: it reads a CSV and, per resource, computes boolean flags indicating whether copyright, licence, and terms are non-empty. The intent is clear, but lack of supporting evidence lowers confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 19105
  },
  {
    "query_id": "musow__sha256:c946098ff3605a4c7999b0c76294018ce8b4fec3ffabdb4c5c9767ff69ef7170",
    "query_label": "musow-0094",
    "kg_id": "musow",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For each resource, which licences and linked licences are associated with it?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "The SPARQL clearly groups by resource and aggregates licence and linked_licence values, so the question reflects this structure. Confidence is limited by the absence of supporting natural-language evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 5822
  },
  {
    "query_id": "jazzontology__sha256:baf1552a9551d50b0a05fe6b91929e1475be5305817c3399adf8c9e58604d5f8",
    "query_label": "jazzontology-0001",
    "kg_id": "jazzontology",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "For a given release title, disc number, and track number, which performance is captured on that track, and what is the track title?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 74,
      "confidence_rationale": "The SPARQL clearly filters by release title, disc (record) number, and track number, then returns the performance captured by the recording published as that track along with the track’s title. No provided evidence directly matches this query’s intent, so the question is generated from the query structure, reducing confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 14437
  },
  {
    "query_id": "jazzontology__sha256:8935c1e59bc7b3a32c2ec259e8ae02e8541e49ff5585d7888c71d9f93a9f92c5",
    "query_label": "jazzontology-0002",
    "kg_id": "jazzontology",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Which album has the given title?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 68,
      "confidence_rationale": "No suitable evidence matches this simple lookup by album title, so the question is generated directly from the SPARQL structure. The query clearly selects albums (mo:SignalGroup) with a specified dc:title, but lack of corroborating evidence lowers confidence slightly.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 10642
  },
  {
    "query_id": "jazzontology__sha256:366607c860b665e511918ad145b2d3f4549ca818cb548dfe555056e16c2b3989",
    "query_label": "jazzontology-0003",
    "kg_id": "jazzontology",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Which release event has the given title and occurred at the specified time?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 66,
      "confidence_rationale": "The SPARQL clearly selects a mo:ReleaseEvent filtered by a specific dc:title and an exact timestamp via tl:at. No provided evidence directly matches this intent, so the question is generated from the query structure, yielding moderate confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 18500
  },
  {
    "query_id": "jazzontology__sha256:e4545ef078881d54eddbe0a0731105355e85b0e849813e6e4d7be35e84f088ac",
    "query_label": "jazzontology-0004",
    "kg_id": "jazzontology",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Which record label has the given title?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No relevant natural-language evidence matches this query. The SPARQL clearly selects a mo:Label resource whose dc:title equals a provided string, so the generated question reflects that intent, but confidence is reduced due to lack of supporting evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 9071
  },
  {
    "query_id": "jazzontology__sha256:2057d9ed00db0d9a636513f5fc4c2e1307fddd100df52f94ec01cb0cb6906085",
    "query_label": "jazzontology-0005",
    "kg_id": "jazzontology",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Which releases have a given title and number of records?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 68,
      "confidence_rationale": "No suitable evidence matches this query. The question is generated directly from the SPARQL, which selects mo:Release entities filtered by dc:title and mo:record_count.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 19546
  },
  {
    "query_id": "jazzontology__sha256:d1ed9b246504a0fa54aa0b567af76ea328ea6ce012801295741984683bc91b7b",
    "query_label": "jazzontology-0006",
    "kg_id": "jazzontology",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Which record has the specified title and record number?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 69,
      "confidence_rationale": "No suitable evidence matches this query, but the SPARQL clearly targets a mo:Record identified by a given title and record number. The generated question faithfully reflects this intent, though confidence is reduced due to lack of supporting text evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 22419
  },
  {
    "query_id": "jazzontology__sha256:486bc0eea004fcba6ff521b36b628808c8a1b7704a1a52e70341a3569fb25767",
    "query_label": "jazzontology-0007",
    "kg_id": "jazzontology",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "Track is implemented as the Music Ontology class Track (mo:Track); stands for a track on a CD",
          "evidence_id": "e16",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": false
        },
        {
          "text": "tracks on a CD",
          "evidence_id": "e4",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": false
        }
      ],
      "nl_question": "Which tracks are on the given CD?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e16",
          "e4"
        ],
        "primary_evidence_id": "e16"
      },
      "confidence": 78,
      "confidence_rationale": "The SPARQL selects resources of type mo:Track linked from a given entity, which aligns with the concept definition that mo:Track stands for a track on a CD. Evidence directly mentions tracks on a CD but does not specify the mo:track property, so some inference is required.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 17257
  },
  {
    "query_id": "jazzontology__sha256:a1ff386839e6acf7863337f1a1db6f313a66440a3961d0b85bcaf973890df890",
    "query_label": "jazzontology-0008",
    "kg_id": "jazzontology",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "What is the band line-up for the given performance?",
          "evidence_id": "e5",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": true
        }
      ],
      "nl_question": "What is the band line-up for the given performance?",
      "nl_question_origin": {
        "mode": "verbatim",
        "evidence_ids": [
          "e5"
        ],
        "primary_evidence_id": "e5"
      },
      "confidence": 90,
      "confidence_rationale": "The query selects entities of type dtl:Performer linked via mo:performer to a given resource, which aligns directly with the CQ asking for the band lineup of a performance. The retained phrase is a strong semantic match, though instruments are not included, which matches the query’s scope.",
      "needs_review": false
    },
    "model": "gpt-5",
    "elapsed_ms": 13573
  },
  {
    "query_id": "jazzontology__sha256:9dc2120315ccc1b971409f1371cdda2c0ff1cd4095a5195e867ba92be47bb28b",
    "query_label": "jazzontology-0009",
    "kg_id": "jazzontology",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Who composed the given tune?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 68,
      "confidence_rationale": "The SPARQL clearly retrieves the composer of a specified resource via dtl:composed_by, but none of the provided CQ items mention composers. The question is therefore generated from the query structure, lowering confidence due to lack of supporting evidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 8944
  },
  {
    "query_id": "jazzontology__sha256:7f7bd57ea80aec101249cabb1c8afb85e35e96d225208a52834b966ae4d8b1d9",
    "query_label": "jazzontology-0010",
    "kg_id": "jazzontology",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Which musician with the given name has composed at least one musical work?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "The SPARQL clearly selects a MusicArtist by a given name who is linked as the composer of at least one MusicalWork. No provided evidence directly addresses composers, so the question is generated from the query structure, reducing confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 11836
  },
  {
    "query_id": "jazzontology__sha256:87bfc7d4d45e0ce2d120c26fcffd3f4f9f93a00083ffcbe463774fc75329927e",
    "query_label": "jazzontology-0011",
    "kg_id": "jazzontology",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Which musician with the given name has arranged at least one musical work?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 63,
      "confidence_rationale": "No suitable natural-language evidence matches the query. The question is generated from the SPARQL, which filters a musician by name and requires they arranged some musical work, returning that musician entity.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 10660
  },
  {
    "query_id": "jazzontology__sha256:0d93c0d329f6775b816fcd0d9ca3d7400fc610cd59785a7820329d3b7ad8df83",
    "query_label": "jazzontology-0012",
    "kg_id": "jazzontology",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Which music group has the given name?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 72,
      "confidence_rationale": "The SPARQL clearly retrieves a mo:MusicGroup whose foaf:name matches a supplied string. No provided evidence directly addresses querying a band by its name, so the question is generated from the query structure.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 10568
  },
  {
    "query_id": "jazzontology__sha256:7d5e9537002932f0adb9b7c3418fa01b87937b6e5645d4f9d681406bbc29de7b",
    "query_label": "jazzontology-0013",
    "kg_id": "jazzontology",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Which musician with the given name performed in the same session as the specified performer?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No direct evidence describes this query, so the question is generated from the SPARQL structure. The query clearly checks for a musician (by name) who performed in a performance within a session that also had a given performer, but the absence of supporting NL evidence reduces confidence.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 19935
  },
  {
    "query_id": "jazzontology__sha256:58569fc597b79a258df3472ceb3582fc162cd8cb88796ad3ebd9bce038b409e9",
    "query_label": "jazzontology-0014",
    "kg_id": "jazzontology",
    "llm_output": {
      "ranked_evidence_phrases": [],
      "nl_question": "Given a release title, record number, and track number, what is the track’s title and which audio signal was published as that track?",
      "nl_question_origin": {
        "mode": "generated",
        "evidence_ids": [],
        "primary_evidence_id": null
      },
      "confidence": 70,
      "confidence_rationale": "No suitable natural-language evidence matches this query, so the question is generated from the SPARQL structure. The query clearly filters by release title, record number, and track number, and returns the track title and the associated audio signal.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 14987
  },
  {
    "query_id": "jazzontology__sha256:d5175a52bce8a637032e68f64db9a287827e8a4bc99707e02d1d65f503b072ff",
    "query_label": "jazzontology-0015",
    "kg_id": "jazzontology",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "What is the band line-up for the given performance?",
          "evidence_id": "e3",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": true
        }
      ],
      "nl_question": "Which musicians were in the band lineup for the session featuring a given performer?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e3"
        ],
        "primary_evidence_id": "e3"
      },
      "confidence": 80,
      "confidence_rationale": "The query selects musicians associated with performances within a session linked to a given performer, which aligns well with the CQ about determining a band lineup. Some inference was needed because the SPARQL uses a given performer and does not include instruments, while the CQ mentions a given performance and instruments.",
      "needs_review": true
    },
    "model": "gpt-5",
    "elapsed_ms": 16246
  },
  {
    "query_id": "jazzontology__sha256:4d2ff7ccf095c2fd94f789b37989aebeba6953d01d45667a9b6f46d8cff360ed",
    "query_label": "jazzontology-0016",
    "kg_id": "jazzontology",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "What is the band line-up for a given track? Who played which instruments?",
          "evidence_id": "e15",
          "source_type": "doc_query_desc",
          "rank": 1,
          "verbatim": false
        },
        {
          "text": "What is the band line-up for the given performance? Who played which instruments?",
          "evidence_id": "e3",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": false
        }
      ],
      "nl_question": "For the track \"Zealot\", who played which instruments?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e15",
          "e3"
        ],
        "primary_evidence_id": "e15"
      },
      "confidence": 95,
      "confidence_rationale": "The SPARQL selects musician names and instrument labels for a specific track title, which directly matches the doc query description about band line-up and instruments for a given track. Supporting CQ evidence reinforces the same intent; only minor paraphrasing was needed to include the concrete track title.",
      "needs_review": false
    },
    "model": "gpt-5",
    "elapsed_ms": 12153
  },
  {
    "query_id": "jazzontology__sha256:f25cfe5e39d227f7c6203ebeb493fdd0967288cbd15f7105f9e9fbd84085a51b",
    "query_label": "jazzontology-0017",
    "kg_id": "jazzontology",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "Which bands played/recorded a given tune?",
          "evidence_id": "e15",
          "source_type": "doc_query_desc",
          "rank": 1,
          "verbatim": true
        },
        {
          "text": "Which bands played/recorded a given tune?",
          "evidence_id": "e4",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": true
        }
      ],
      "nl_question": "Which bands played or recorded the tune \"Caravan,\" and on what date?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e15",
          "e4"
        ],
        "primary_evidence_id": "e15"
      },
      "confidence": 88,
      "confidence_rationale": "The SPARQL selects band names and session dates for performances of the tune titled \"Caravan.\" This closely matches CQ3 about which bands played/recorded a given tune; the question is paraphrased to include the date returned by the query.",
      "needs_review": false
    },
    "model": "gpt-5",
    "elapsed_ms": 14773
  },
  {
    "query_id": "jazzontology__sha256:9120751047ee116a87d3d794aab03106ef9a403c6241bc53278ef24c57b6a3a4",
    "query_label": "jazzontology-0018",
    "kg_id": "jazzontology",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "Which instruments has a given performer played?",
          "evidence_id": "e15",
          "source_type": "doc_query_desc",
          "rank": 1,
          "verbatim": false
        },
        {
          "text": "Which instruments has a given performer played?",
          "evidence_id": "e5",
          "source_type": "cq_item",
          "rank": 2,
          "verbatim": false
        },
        {
          "text": "Who played which instruments?",
          "evidence_id": "e3",
          "source_type": "cq_item",
          "rank": 3,
          "verbatim": false
        }
      ],
      "nl_question": "Which instruments did Dizzy Gillespie play?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e15",
          "e5",
          "e3"
        ],
        "primary_evidence_id": "e15"
      },
      "confidence": 95,
      "confidence_rationale": "The SPARQL selects instrument labels for the musician named Dizzy Gillespie, which directly matches the documented question about instruments played by a given performer. Multiple high-priority evidence items (doc_query_desc and cq_item) align precisely with the query’s intent.",
      "needs_review": false
    },
    "model": "gpt-5",
    "elapsed_ms": 7885
  },
  {
    "query_id": "jazzontology__sha256:6ef8e208e3db08a0c274ffbcdd2d928cfa4c528a0cc5d3369d19f5dfe478e815",
    "query_label": "jazzontology-0019",
    "kg_id": "jazzontology",
    "llm_output": {
      "ranked_evidence_phrases": [
        {
          "text": "Find performances whose recordings resulted in the same audio",
          "evidence_id": "e6",
          "source_type": "cq_item",
          "rank": 1,
          "verbatim": false
        }
      ],
      "nl_question": "Which pairs of recordings share the same audio fingerprint?",
      "nl_question_origin": {
        "mode": "paraphrased",
        "evidence_ids": [
          "e6"
        ],
        "primary_evidence_id": "e6"
      },
      "confidence": 88,
      "confidence_rationale": "The SPARQL finds two different mo:Signal instances with an identical short fingerprint, aligning with CQ5’s intent to identify recordings that are the same audio. Minor abstraction from \"performances\" to \"recordings/signals\" introduces slight ambiguity, but the match is strong.",
      "needs_review": false
    },
    "model": "gpt-5",
    "elapsed_ms": 11369
  }
]
